{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab8003e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CIS-660 Lab 2 Assignment\n",
    "Author: Mohamed Gani Mohamed Sulthan\n",
    "CSU ID: 2811619\n",
    "Major: Master’s in computer science\n",
    "'''\n",
    "# Import all the required modules\n",
    "import requests\n",
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import operator\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d02f06c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Frequency Finding Process Started:\n",
      "research appears 6 times\n",
      "data appears 20 times\n",
      "mining appears 0 times\n",
      "analytics appears 0 times\n",
      "datamining appears 0 times\n",
      "machinelearning appears 20 times\n",
      "deeplearning appears 0 times\n",
      "Appending total words count for 6 files for seven words in an array [[6, 20, 0, 0, 0, 20, 0]]\n",
      "research appears 14 times\n",
      "data appears 5 times\n",
      "mining appears 3 times\n",
      "analytics appears 0 times\n",
      "datamining appears 0 times\n",
      "machinelearning appears 0 times\n",
      "deeplearning appears 0 times\n",
      "Appending total words count for 6 files for seven words in an array [[6, 20, 0, 0, 0, 20, 0], [14, 5, 3, 0, 0, 0, 0]]\n",
      "research appears 38 times\n",
      "data appears 1 times\n",
      "mining appears 0 times\n",
      "analytics appears 0 times\n",
      "datamining appears 0 times\n",
      "machinelearning appears 0 times\n",
      "deeplearning appears 0 times\n",
      "Appending total words count for 6 files for seven words in an array [[6, 20, 0, 0, 0, 20, 0], [14, 5, 3, 0, 0, 0, 0], [38, 1, 0, 0, 0, 0, 0]]\n",
      "research appears 9 times\n",
      "data appears 100 times\n",
      "mining appears 16 times\n",
      "analytics appears 2 times\n",
      "datamining appears 175 times\n",
      "machinelearning appears 57 times\n",
      "deeplearning appears 4 times\n",
      "Appending total words count for 6 files for seven words in an array [[6, 20, 0, 0, 0, 20, 0], [14, 5, 3, 0, 0, 0, 0], [38, 1, 0, 0, 0, 0, 0], [9, 100, 16, 2, 175, 57, 4]]\n",
      "research appears 9 times\n",
      "data appears 100 times\n",
      "mining appears 16 times\n",
      "analytics appears 2 times\n",
      "datamining appears 175 times\n",
      "machinelearning appears 57 times\n",
      "deeplearning appears 4 times\n",
      "Appending total words count for 6 files for seven words in an array [[6, 20, 0, 0, 0, 20, 0], [14, 5, 3, 0, 0, 0, 0], [38, 1, 0, 0, 0, 0, 0], [9, 100, 16, 2, 175, 57, 4], [9, 100, 16, 2, 175, 57, 4]]\n",
      "research appears 24 times\n",
      "data appears 67 times\n",
      "mining appears 1 times\n",
      "analytics appears 18 times\n",
      "datamining appears 2 times\n",
      "machinelearning appears 16 times\n",
      "deeplearning appears 3 times\n",
      "Appending total words count for 6 files for seven words in an array [[6, 20, 0, 0, 0, 20, 0], [14, 5, 3, 0, 0, 0, 0], [38, 1, 0, 0, 0, 0, 0], [9, 100, 16, 2, 175, 57, 4], [9, 100, 16, 2, 175, 57, 4], [24, 67, 1, 18, 2, 16, 3]]\n"
     ]
    }
   ],
   "source": [
    "# Define the location of the directory\n",
    "path =r\"C:/Users/Gani/Desktop/Cleveland State University/Third Sem/Data Mining/Lab/Lab 2/\"\n",
    "\n",
    "# Change the directory\n",
    "os.chdir(path)\n",
    "list = []\n",
    "wordsCountAll = []\n",
    "stemWordList = []\n",
    "wordlist = []\n",
    "\n",
    "def read_files(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as file:\n",
    "        contents = file.read()\n",
    "\n",
    "        # Breaking into lines and remove leading and trailing space and  multi-headlines and blank lines\n",
    "        lines = (line.strip() for line in contents.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        \n",
    "        # Removing hyper link and regular expressions\n",
    "        hyperlink_removed_text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '',text)\n",
    "        te = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        pattern = r'[0-9]'\n",
    "        new_text = re.sub(pattern, '', te)\n",
    "        lowerCaseText = new_text.lower()\n",
    "        \n",
    "        # Making the bigrams of the word by combining it\n",
    "        bigram_word1=re.sub('data mining',' datamining ', lowerCaseText)\n",
    "        bigram_word2=re.sub('deep learning',' deeplearning ', bigram_word1)\n",
    "        bigram_word3=re.sub('machine learning',' machinelearning ', bigram_word2)\n",
    "        \n",
    "        # Removing unnecessary special characters and Splitting the details and put into list\n",
    "        final= re.sub(\"\\s\\s+\", \" \", bigram_word3)\n",
    "        final2= re.sub(\"–\", \"\", final)\n",
    "        final3=re.sub('[^a-zA-Z0-9 \\n\\.]', ' ',final2)\n",
    "        \n",
    "        # Putting the words in the list\n",
    "        words_list = final3.split()\n",
    "        \n",
    "        # Removing stopwords and putting into the filtered_words\n",
    "        filtered_words = [word for word in words_list if word not in stopwords.words('english')]\n",
    "        \n",
    "        # stemming\n",
    "        ps = PorterStemmer()\n",
    "        words = word_tokenize(new_text)\n",
    "        for w in words:\n",
    "            wordlist.append(w)\n",
    "            stemWordList.append(ps.stem(w))\n",
    "        \n",
    "        # Counting the values using pandas and matcing with the documents \n",
    "        count = pd.value_counts(np.array(filtered_words))\n",
    "        words_find = ['research','data','mining', 'analytics', 'datamining', 'machinelearning', 'deeplearning']\n",
    "        wordscount = []\n",
    "        doc = 0\n",
    "        for i in words_find:\n",
    "            print(i, \"appears\", filtered_words.count(i), \"times\" )\n",
    "            wordscount.append(filtered_words.count(i))\n",
    "            \n",
    "        wordsCountAll.append(wordscount.copy())\n",
    "        print(\"Appending total words count for 6 files for seven words in an array\", wordsCountAll)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Iterate over all the files in the directory\n",
    "    print(\"Document Frequency Finding Process Started:\")\n",
    "    for file in os.listdir():\n",
    "        if file.endswith('.txt'):\n",
    "            # Create the filepath of particular file\n",
    "            file_path =f\"{path}/{file}\"\n",
    "            read_files(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60e8dd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Visualization for the seven words in six docs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>research</th>\n",
       "      <th>data</th>\n",
       "      <th>mining</th>\n",
       "      <th>analytics</th>\n",
       "      <th>datamining</th>\n",
       "      <th>machinelearning</th>\n",
       "      <th>deeplearning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc4</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc5</th>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc6</th>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      research  data  mining  analytics  datamining  machinelearning  \\\n",
       "doc1         6    20       0          0           0               20   \n",
       "doc2        14     5       3          0           0                0   \n",
       "doc3        38     1       0          0           0                0   \n",
       "doc4         9   100      16          2         175               57   \n",
       "doc5         9   100      16          2         175               57   \n",
       "doc6        24    67       1         18           2               16   \n",
       "\n",
       "      deeplearning  \n",
       "doc1             0  \n",
       "doc2             0  \n",
       "doc3             0  \n",
       "doc4             4  \n",
       "doc5             4  \n",
       "doc6             3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"DataFrame Visualization for the seven words in six docs:\")\n",
    "df = pd.DataFrame(wordsCountAll, columns = ['research','data','mining', 'analytics', 'datamining', 'machinelearning', 'deeplearning'])\n",
    "df.index = ['doc1','doc2','doc3','doc4','doc5','doc6']\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa4cd0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity for Six documents:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>doc3</th>\n",
       "      <th>doc4</th>\n",
       "      <th>doc5</th>\n",
       "      <th>doc6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419615</td>\n",
       "      <td>0.225639</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.829399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>0.419615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931486</td>\n",
       "      <td>0.211316</td>\n",
       "      <td>0.211316</td>\n",
       "      <td>0.590780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc3</th>\n",
       "      <td>0.225639</td>\n",
       "      <td>0.931486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.055287</td>\n",
       "      <td>0.055287</td>\n",
       "      <td>0.342357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc4</th>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.211316</td>\n",
       "      <td>0.055287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc5</th>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.211316</td>\n",
       "      <td>0.055287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.520954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc6</th>\n",
       "      <td>0.829399</td>\n",
       "      <td>0.590780</td>\n",
       "      <td>0.342357</td>\n",
       "      <td>0.520954</td>\n",
       "      <td>0.520954</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          doc1      doc2      doc3      doc4      doc5      doc6\n",
       "doc1  1.000000  0.419615  0.225639  0.525253  0.525253  0.829399\n",
       "doc2  0.419615  1.000000  0.931486  0.211316  0.211316  0.590780\n",
       "doc3  0.225639  0.931486  1.000000  0.055287  0.055287  0.342357\n",
       "doc4  0.525253  0.211316  0.055287  1.000000  1.000000  0.520954\n",
       "doc5  0.525253  0.211316  0.055287  1.000000  1.000000  0.520954\n",
       "doc6  0.829399  0.590780  0.342357  0.520954  0.520954  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Cosine Similarity for Six documents:\")\n",
    "cos_df = pd.DataFrame(cosine_similarity(df))\n",
    "cos_df.index = ['doc1','doc2','doc3','doc4','doc5','doc6']\n",
    "cos_df.columns = ['doc1','doc2','doc3','doc4','doc5','doc6']\n",
    "display(cos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baadd064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
